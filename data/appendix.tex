\chapter{外文资料原文}
\label{cha:engorg}

\title{OptiX: A General Purpose Ray Tracing Engine}

\section{Programmable Ray Tracing Pipeline}

The core idea of the OptiX engine is that most ray tracing algorithms can be implemented using a small set of programmable operations. This is a direct analog to the programmable rasterization pipelines employed by OpenGL and Direct3D. At a high level,
those systems expose an abstract rasterizer containing lightweight
callbacks for vertex shading, geometry processing, tessellation, and
fragment shading operations. An ensemble of these program types,
typically used in multiple passes, can be used to implement a broad
variety of rasterization-based algorithms.

We have identified a corresponding abstract ray tracing execution model along with lightweight operations that can be customized to implement a wide variety of ray tracing-based algorithms. [NVIDIA 2010a]. These operations, or programs, can be
combined with a user-defined data structure (payload) associated
with each ray. The ensemble of programs conspire to implement a
particular client application’s algorithm.

\subsection{Programs}

There are seven different types of programs in OptiX, each of which
operates on a single ray at a time. In addition, a bounding box program operates on geometry to determine primitive bounds for acceleration structure construction. The combination of user programs
and hardcoded OptiX kernel code forms the ray tracing pipeline,
which is outlined in Figure 2. Unlike a feed-forward rasterization
pipeline, it is more natural to think of the ray tracing pipeline as a
call graph. The core operation, rtTrace, alternates between locating an intersection (Traverse) and responding to that intersection
(Shade). By reading and writing data in user-defined ray payloads
and in global device memory arrays (buffers, see section 3.5), these
operations are combined to perform arbitrary computation during
ray tracing.

Ray generation programs are the entry into the ray tracing pipeline.
A single invocation of rtContextLaunch will create many instantiations of these programs. In the example in Figure 3, a ray generation program will create a ray using a pinhole camera model for
a single pixel, start a trace operation, and store the resulting color
in an output buffer. With this mechanism, one can also perform
other operations such as creating photon maps, computing baked
lighting, processing ray requests passed from OpenGL, shooting
multiple rays for super-sampling, or implementing different camera models.

Intersection programs implement ray-geometry intersection tests.
As the acceleration structures are traversed, the system will invoke
an intersection program to perform the geometric query. The program determines if and where the ray touches the object and may
compute normals, texture coordinates, or other attributes based on
the hit position. An arbitrary number of attributes may be associated with each intersection. Intersection programs enable support for arbitrary surfaces such as spheres, cylinders, high-order
surfaces, or even fractal geometries like the Julia set in Figure 1.
However, even in a triangle-only system, one may encounter a wide
variety of mesh representations. A programmable intersection operation facilitates direct access to the native format, which can help
avoid copies when interoperating with rasterization-based systems.

Bounding box programs compute the bounds associated with each
primitive to enable acceleration structures over arbitrary geometry.
Given a primitive index, a simple program of this type may, for
example, read vertex data from a buffer and compute a triangle’s
bounding box. Procedural geometry can sometimes only estimate
the bounds of a primitive. Such estimates are allowed as long as
they are conservative, but loose bounds may degrade performance.

Closest hit programs are invoked once traversal has found the closest intersection of a ray with the scene geometry. This program
type closely resembles surface shaders in classical rendering systems. Typically, a closest hit program will perform computations
like shading, potentially casting new rays in the process, and store
result data in the ray payload.

Any hit programs are called during traversal for every ray-object
intersection that is found. The any hit program allows the material to participate in object intersection decisions while keeping the shading operations separate from the geometry operations. It may optionally terminate the ray using the built-in function rtTerminateRay, which will stop all traversal and unwind the
call stack to the most recent invocation of rtTrace. This is a
lightweight exception mechanism that can be used to implement
early ray termination for shadow rays and ambient occlusion. Alternatively, the any hit program may ignore the intersection using rtIgnoreIntersection, allowing traversal to continue looking for
other geometric objects. An intersection may be ignored, for instance, 
based on a texture channel lookup, 
thus implementing efficient alpha-mapped transparency without restarting traversal. 
Another use case for the any hit program can be found in Section 8.1,
where the application performs visibility attenuation for partial
shadows cast by glass objects. Note that intersections may be presented out of order. The default any hit program is a no-op, which
is often the desired operation.

Miss programs are executed when the ray does not intersect any
geometry in the interval provided. They can be used to implement
a background color or environment map lookup.

Exception programs are executed when the system encounters an
exceptional condition, e.g., when the recursion stack exceeds the
amount of memory available for each thread, or when a buffer access index is out of range. OptiX also supports user-defined exceptions that can be thrown from any program. The exception program
can react, for example, by printing diagnostic messages or visualizing the condition by writing special color values to an output pixel
buffer.

Selector visit programs expose programmability for coarse-level
node graph traversal. For example, an application may choose to
vary the level of geometric detail for parts of the scene on a perray basis. In this case, the visit program would examine the ray
distance or a ray differential stored with the payload and make a
traversal decision based on that data.

\subsection{Scene representation}

The OptiX engine employs a flexible structure for representing
scene information and associated programmable operations, collected in a container object called the context. This representation is also the mechanism for binding programmable shaders to
the object-specific data that they require. In conjunction with a
special-purpose object model described in Section 3.3, a compact
representation of scene data is achieved.

\subsubsection{Hierarchy nodes}

A scene is represented as a graph. This representation is very
lightweight and controls the traversal of rays through the scene. It
can also be used to implement instancing two-level hierarchies for
animations of rigid objects, or other common scene structures. To
support instancing and sharing of common data, the nodes can have
multiple parents.

Four main node types can be used to provide the scene representation using a directed graph. Any node can be used as the root of
scene traversal. This allows, for example, different representations
to be used for different ray types.

Group nodes contain zero or more (but usually two or more) children of any node type. A group node has an acceleration structure
associated with it and can be used to provide the top level of a twolevel traversal structure.

Geometry Group nodes are the leaves of the graph and contain the
primitive and material objects described below. This node type also
has an acceleration structure associated with it. Any non-empty
scene will contain at least one geometry group.

Transform nodes have a single child of any node type, plus an associated 4×3 matrix that is used to perform an affine transformation
of the underlying geometry.

Selector nodes have zero or more children of any node type, plus a
single visit program that is executed to select among the available
children. Although not implemented in the current version of the
OptiX libraries, the node graph can be cyclic if the selector node is
used carefully to avoid infinite recursion.

\subsubsection{Geometry and material objects}

The bulk of the data is stored in the geometry nodes at the leaves of
the graph. These contain objects that define geometry and shading
operations. They may also have multiple parents, allowing material
and geometry information to be shared at multiple points in the
graph; for a complete example, see Figure 4.

Geometry Instance objects bind a geometry object to a set of material objects. This is a common structure used by scene graphs to
keep geometric and shading information orthogonal.

Geometry objects contain a list of geometric primitives. Each geometry object is associated with a bounding box program and an
intersection program, both of which are shared among the geometry object’s primitives.

Material objects hold information about shading operations, including programs called for each intersection as they are discovered
(any hit program) and for the intersection nearest to the origin of a
given ray (closest hit program).

\subsection{ Object and data model}

OptiX employs a special-purpose object model designed to minimize the constant data used by the programmable operations. In
contrast to an OpenGL system, where only a single combination
of shaders is used at a time. However, ray tracing can randomly
access object and material data. Therefore, instead of the uniform
variables employed by OpenGL shading languages, OptiX allows
any of the objects and nodes described above to carry an arbitrary
set of variables expressed as a typed name-value pair called a variable. Variables are set by the client application and have read-only
access during the execution of a trace. Variables can be of scalar or
vector integer and floating point types (e.g., float3, int4) as well as
user-defined structs and references to buffers and texture samplers.

The inheritance mechanism for these variables is unique to OptiX.
Instead of a class-based inheritance model with a single self or this
pointer, the OptiX engine tracks the current geometry and material
objects and the current traversal node. Variable values are inherited
from the objects that are active at each point in the control flow. For
example, an intersection program will inherit definitions from the
geometry and geometry instance objects, in addition to global variables defined in the context. Conceptually, OptiX examines each
of these objects for a matching name/value pair when a variable is
accessed. This mechanism can be thought of as a generalization of
nested scoping found in most programming languages. It can also
be implemented quite efficiently in the just-in-time compiler.

As an example of how this is useful, consider an array of light
sources called lights. Typically, a user would define lights in the
context, the global scope of OptiX. This makes this value available in all shaders in the entire scene. However, if the lights for
a particular object need to be overridden, another variable of the
same name can be created and attached to the geometry instance
associated with that object. In this way, programs connected to that
object would use the overridden value of lights rather than the value
attached to the context. This is a powerful mechanism that can be
used to minimize the scene data to enable high performance on architectures with minimal caches. The manner in which these cases
are handled can vary dramatically from one renderer to another, so
the OptiX engine provides the basic functionality to express any
number of override rules efficiently.

A special type of variable, tagged with the keyword attribute can be
used to communicate information from the intersection program to
the closest- and any-hit programs. These are analogous to OpenGL
varying variables, and are used for communicating texture coordinates, normals and other shading information from the intersection
programs to the shading programs. These variables have special semantics — they are written by the intersection program but only the
values associated with the closest intersection are kept. This mechanism enables the intersection operation to be completely separate
from the shading operations, enabling multiple simultaneous primitives and/or mesh storage formats while still supporting texturing,
shading normals, and object curvatures for ray differentials. Attributes that are not used by any closest- or any-hit program can be
elided by the OptiX compiler.

\subsection{ Dynamic dispatch}

To allow multiple ray-tracing operations to co-exist in a single execution, OptiX employs a user-defined ray type. A ray type is simply
an index that selects a particular set of slots for any hit and closest
hit programs to be executed when an intersection is found. This can
be used, for example, to treat shadow rays separately from other
rays.


Similarly, multiple entry points in an OptiX context enable an efficient way to represent different passes over the same set of geometry. For example, a photon mapper may use one entry point to
cast photons into the scene and a second entry point to cast viewing
rays.

\subsection{ Buffers and Textures}

The key abstraction for bulk data storage is the multi-dimensional
buffer object, which presents a 1-, 2- or 3-dimensional array of a
fixed element size. A buffer is accessed through a C++ wrapper
object in any of the programs. Buffers can be read-only, write-only
or read-write and support atomic operations when supported by the
hardware. A buffer is handle-based and does not expose raw pointers, thus enabling the OptiX runtime to relocate buffers for storage
compaction, or for promotion to other memory spaces for performance. Buffers are typically used for output images, triangle data,
light source lists, and other array-based data. Buffers are the sole
means of outputing data from an OptiX program. In most applications, the ray generation program will be responsible for writing
data to the output buffer, but any of the OptiX programs are allowed
to write to output buffers at any location, but with no ordering guarantees.
A buffer can also be bound to a texture sampler object, which will
utilize the GPU texturing hardware. Buffers and texture sampler
objects are bound to OptiX variables and utilize the same scoping
mechanisms as shader values. Additionally, both buffers and texture samplers can interoperate with OpenGL and DirectX, enabling
efficient implementation of hybrid rasterization/raytracing applications.

\section{System Overview}

The OptiX engine consists of two distinct APIs, one for host-side
and one for device-side code.1 The host API is a set of C functions that the client application calls to create and configure a context, assemble a node graph, and launch ray tracing kernels. It also
provides calls to manage devices used for kernel execution. The
program API is the functionality exposed to user programs. This
includes function calls for tracing rays, reporting intersections, and
accessing data. In addition, several semantic variables encode state
specific to ray tracing, e.g., the current distance to the closest intersection. Printing and exception handling facilities are also available
for debugging.

Figure 5 outlines the control flow of an OptiX application. During setup, the application calls OptiX host API functions to provide scene data data such as geometry, materials, acceleration structures, hierarchical relationships, and programs. A subsequent call
to the rtContextLaunch API function passes control to OptiX, where
changes in the context are processed. If required, a new ray tracing kernel is compiled from the given user programs. Acceleration
structures are built (or updated) and data is synchronized between
host and device memory. Finally, the ray tracing kernel is executed,
invoking the various user programs as described in Section 3.

After execution of the ray tracing kernel has finished, its result data
can be used by the application. Typically, this involves reading
from output buffers filled by one of the user programs or displaying
such a buffer directly, e.g., via OpenGL. An interactive or multipass application then repeats the process starting at context setup,
where arbitrary changes to the context can be made, and the kernel
is launched again.

\section{Acceleration Structures}

The core algorithm for finding an intersection between a ray and
the scene geometry involves the traversal of acceleration structures.
Such data structures are a vital component of virtually every ray
tracing system. They are usually spatial or object hierarchies and
are used by the traversal algorithm to efficiently search for primitives that potentially intersect a given ray. OptiX offers a flexible
interface, suitable for a wide range of applications, to control its
acceleration structures.

\subsection{Interaction with the node graph}

One of the reasons for collecting geometry data in a node graph is to
facilitate the organization of the associated acceleration structures.
Instead of maintaining all scene geometry within a single acceleration structure, it often makes sense to build several structures over
different regions of the scene. For example, parts of the scene may
be animated, requiring an acceleration structure to be rebuilt for every ray tracing pass. In this case, creating a separate structure for
the static regions of the scene can increase efficiency. In addition
to only constructing the static structure once, the application can
typically invest a larger time budget into a higher quality build.

The OptiX engine associates acceleration structures with all groups
and geometry groups in the node graph. Structures attached to geometry groups are low level, built over the geometric primitives the
geometry group contains. Structures on groups are built over the
bounds of the children of that group and thus represent high level
acceleration structures. These high level structures are useful to express hierarchical relationships between geometry that is modified
at different rates.

Instancing. An important design goal for the acceleration structure system was support for flexible instancing. Here, instancing
refers to low-overhead replication of scene geometry by referencing
the same data more than once, without having to copy heavyweight
data structures. As described in Section 3.2.1, nodes in the graph
can be referenced multiple times, which naturally implements instancing. It is desirable to not only share geometry information
among instances, but acceleration structures as well. At the same
time, it should be possible to assign non-geometry data such as material programs and variables independently for each instance.

We chose to expose acceleration structures as separate API objects
that are attached to groups and geometry groups. In the instancing
case, it is possible to attach a single acceleration structure to multiple nodes, thus sharing its data and avoiding redundant construction of the same data structure. The method also results in efficient
addition and removal of instances at runtime. Figure 6 shows an
example of a node graph with instancing.

Acceleration structures on combined geometry. Dividing the
scene into multiple acceleration structures reduces structure build
time but also reduces ray traversal performance. In the limiting
case of an entirely static scene, one would typically choose a single
acceleration structure. One idea behind acceleration structures on
geometry groups is to facilitate the application’s data management
for that type of setup: instead of having to merge individual geometric objects into a monolithic chunk, they can stay organized as
separate geometries and instances, and easily be collected within
a single geometry group. The corresponding acceleration structure
will be built over the individual primitives of any geometric objects,
resulting in maximum efficiency as if all the geometry were combined. The OptiX engine will internally take care of the necessary
bookkeeping tasks, such as correct remapping of material indices.

A geometry group can also exploit certain per-object information
when building its acceleration structure. For example, in a geometry group containing multiple objects, only a single one might have
been modified between ray tracing passes. OptiX can take into account that information and omit some redundant operations (e.g.
bounding box computations, see Section 5.3).

\subsection{ Types of acceleration structures}

Ray tracing acceleration structures are an active area of research.
There is no single type that is optimal for all applications under all
conditions. The typical tradeoff between the different variants is
ray tracing performance versus construction speed, and each application has a different optimal balance. Therefore, OptiX provides a
number of different acceleration structure types that the application
can choose from. Each acceleration structure in the node graph can
be of a different type, allowing combinations of high-quality static
structures with dynamically updated ones. Most types are also suitable for high level structures, i.e. acceleration structures attached to
groups.

The currently implemented acceleration structures include algorithms focused on hierarchy quality (e.g. the SBVH [Stich et al.
2009]), on construction speed (e.g. the LBVH [Lauterbach et al.
2009]), and various balance levels in between.

\subsection{Construction}

Whenever the underlying geometry of an acceleration structure is
changed, e.g. during an animation, it is explicitly marked for rebuild by the client application. OptiX then builds the so scheduled
acceleration structures on the subsequent invocation of the rtContextLaunch API function.

The first stage in acceleration structure construction acquires the
bounding boxes of the referenced geometry. This is achieved by
executing for each geometric primitive in an object the bounding
box program described in Section 3.1, which is required to return
a conservative axis-aligned bounding box for its input primitive.
Using these bounding boxes as elementary primitives for the acceleration structures provides the necessary abstraction to trace rays
against arbitrary user-defined geometry (including several types of
geometry within a single structure). To obtain the necessary bounding boxes for higher level group nodes in the tree, the union of the
primitive bounding boxes is formed and propagated recursively.

The second construction stage consist of actually building the required acceleration structures given the obtained bounding boxes.
The available host and device parallelism can be utilized in two
ways. First, multiple acceleration structures in the node graph can
be constructed in parallel, as they are independent. Second, a single
acceleration structure build code can usually be parallelized (see
e.g. [Shevtsov et al. 2007], [Zhou et al. 2008], [Lauterbach et al.
2009]). The final acceleration structure data is placed in device
memory for consumption by the ray traversal code.

\subsection{Tuning}

While acceleration structures in the OptiX engine are designed to
perform well out of the box, it is sometimes necessary for the application to provide additional information to achieve the highest
possible performance. The application can therefore set acceleration structure-specific properties that affect subsequent structure
builds and ray traversals.

One example for such a property is the “refit” flag: if the geometry
used by a BVH acceleration structure has changed only slightly, it is
often sufficient to simply refit the BVH’s internal bounding boxes
instead of rebuilding the full structure from scratch (see [Lauterbach et al. 2006]). The client application can enable this behavior
on certain types of acceleration structures if it assumes the resulting
total runtime will decrease. Such decisions are left to the application, as it usually possesses contextual information that is unavailable to OptiX.

Build procedures specialized to certain types of geometric primitives (as opposed to the axis-aligned bounding boxes discussed
above) are a second case where properties are useful. The application may, for example, inform an SBVH acceleration structure
that the underlying geometry consists exclusively of triangles, and
where these triangles are located in memory. The SBVH can then
perform a more exact method of constructing the hierarchy, which
results in higher quality.

\chapter{外文资料的书面翻译}

\title{OpTiX：一款通用光线追踪引擎}

\section{可编程光线追踪渲染系统}

OptiX引擎的核心思想是大多数光线跟踪算法可以使用一小组可编程操作来实现。 
这与OpenGL和Direct3D采用的可编程光栅化流水线直接相似。
在高层的模型中，这些系统提出了一个抽象的光栅化器，
其中包含一些轻量回调函数（shader）用于顶点着色，几何处理，曲面细分和片段着色操作。
这些程序的集合，可用于实现广泛的各种基于光栅化的算法。

我们的工作则确立了一套与之相似的光线跟踪框架，以及可以定制的简单函数，以实现各种基于光线跟踪的算法。 
[NVIDIA 2010a]。 
这些操作或程序可以允许一个由用户定义的数据结构（有效负载）与光线绑定在一起。 
而所有程序的集合则共同实现了一个针对特定客户端应用的算法。

\subsection{程序}

OptiX中有七种不同类型的程序，每种程序每每次都只在一条光线上运行。
此外，还有一个包围盒程序对几何物体进行操作以确定一个加速结构的边界。
用户程序和OptiX的内核代码（硬编码）的组合构成光线跟踪管线，如图2所示。
与前馈的光栅化管线不同，这个结构将光线跟踪管线视为一种更自然的函数调用图。
该结构中的核心操作，rtTrace函数，在定位交叉点（Traverse部分）和响应交叉点（Shade部分）的两个过程之间交替。
通过在用户定义的负载中，以及在全局的设备存储器阵列（Buffers，详见第3.5节）中读取和写入数据，
这些操作的组合体可以被用于执行任意类型的射线追踪计算。

\textbf{Ray generation programs} 
是光线跟踪管线的入口函数。一次对rtContextLaunch的调用将创建该函数的多个实例。
在图3的示例中，一个Ray generation program将通过针孔相机模型为单个像素创建光线，
然后启动跟踪操作，并将生成的颜色存储在输出缓冲区中。
通过这种机制，人们也可以执行其他操作，如创建光子图，计算烘焙照明，
处理从OpenGL传来的光线请求，为超采样而射击多个光线，或实现不同的相机模型等等。

\textbf{Insection programs} 
实现了光线与几何物体相交的测定工作。当遍历加速结构时，系统将通过该程序完成几何上的查询。
该程序将决定光线是否以及在何处接触物体并且可以计算法线，纹理坐标或关于命中位置的其他属性。
每个相交点都可以关联任意数量的属性。
Insection program支持任意表面，如球体，圆柱体，高阶表面，甚至是分形几何图形，如图1中的Julia集合。
然而，即使在仅有三角形组成的系统中，也可能遇到很多种不同的网格表示方式。
可编程Insection programs则有助于直接访问这些格式，
从而使得用户在与基于光栅化的系统进行交互时避免各种格式之间的转换和复制。

\textbf{Bounding box programs}计算与每个基元相关的包围盒，以在任意几何体上都能启用加速结构。
举例而言，给定一个索引值，一个这类的简单程序便可以从缓冲区读取相应顶点数据然后计算三角形的包围盒。
这类程序有时只能对基元的包围盒做出近似估计，但只要这些估计是保守的便可以使用。
松散的包围盒可能会降低性能。

\textbf{Closest hit programs}
是一类在traversal程序找到光线与场景几何体的最近交点时便会调用的程序。
这个程序的类型与经典渲染系统中的表面着色器非常相似。
一般情况下，Closest hit programs程序将执行诸如着色一类的计算，
并可能投射新的光线，在光线载荷中储存结果数据等等。

\textbf{Any hit programs}
则在traversal程序找到每个光线和场景中几何物体的相交事件时被调用。
Any hit programs使得材质可以支持与几何操作解耦的着色操作。
它可以选择使用内置函数rtTerminateRay终止光线，
这将停止所有traversal和并退回到最近调用rtTrace的地方。
这是一个轻量级异常机制，用于实现阴影射线和环境遮挡的中的射线终止操作。
此外，Any hit programs也可以使用rtIgnoreIntersection忽略相交，从而继续查找其他几何对象。
例如，通过对纹理通道查找的方式忽略相交点的方法，可以实现有效的alpha映射透明度，而无需重新启动遍历。
Any hit programs的另一个用例可以在8.1节中找到，用于执行部分应用程序针对玻璃物体投射阴影的可见性衰减效果。
请注意，这些交叉点可能以随即顺序呈现。默认的Any hit programs是空操作。

\textbf{Miss programs}
当光线在给定的区间内不与任何几何体相交时被执行。它们可以用来实现背景颜色或背景环境图。

\textbf{Exception programs}
当系统遇到异常程序时被执行。例如，
当递归堆栈超过每个线程可用的内存量，或缓冲区访问索引超出范围时的内存量时。 
OptiX还支持可以从任何程序抛出的用户自定义的异常。
Exception programs可以通过例如将特殊颜色值写入输出像素等方法来打印诊断消息或可视化条件缓冲。

\textbf{Selector visit programs}
为粗级的节点图遍历提供了可编程性。
例如，应用程序可以选择在基于perray的基础上改变场景的部分几何细节的级别。 
在这种情况下，Selector visit programs检查光线距离或载荷中存储的光线差异，
并基于该数据进行遍历决定。

\subsection{场景表示}

OptiX引擎采用灵活的结构来表示场景信息和相关的可编程操作，
并将其收集在了称为上下文（context）的容器对象中。
此表示也提供了将编程着色器绑定到需要它们的对应对象数据上的机制。
通过与第3.3节中描述的专用对象模型结合，这里实现了一个一个紧凑的对场景数据的表示。

\subsubsection{分层结构节点}

场景通过一个图结构来表示。这种表示方法即轻量级，又便于控制针对穿过场景的光线的traversal流程。
它也可用于实现用于表示刚性物体动画的两级层次结构，或其他常见场景结构。
为了实现公共数据实例化和共享操作，图中的每个节点可以拥有多个父母。

可以使用四种主要节点类型来使用有向图来提供场景表示。
任何节点都可以用作根场景遍历。这允许例如不同的表示用于不同的射线类型。

\textbf{Group}节点包含任何节点类型的零个或多个（但通常是两个或更多个）子节点。
组节点包含有关联的加速结构，可以被用作于两级遍历结构中的顶层节点。

\textbf{Geometry Group}节点是图的叶子节点，并包含几何原型和物质对象，这些将在下面进一步讲述。
此节点也有具有与之相关的加速结构。任何非空的场景必须至少包含一个Geometry Group。

\textbf{Transform}节点包含任何节点类型的单个子节点，以及用于对底层几何体执行仿射变换的4×3矩阵。

\textbf{Selector}节点具有零个或多个任何节点类型的子节点，加上一个Selector visit program程序，以在可用的子节点中进行选择。
虽然没有实现在当前版本中的OptiX库中，但如果能做到谨慎使用的Selector节点话（避免无限递归），
理论上整个场景图甚至可以构成一个环结构。

\subsubsection{几何和材料对象}

大部分数据存储在作为场景图中叶子节点的几何节点中。
这些节点中含有定义几何体以及着色器的对象。
他们也可能有多个父母，从而允许材质和几何信息在多个节点中共享；
有关完整的示例，请参见图4。

\textbf{Geometry Instance}对象将几何对象(geometry)与一组材质对象(material)进行绑定。
这是场景图使用的常见结构, 能够保持几何信息和着色器信息做到正确匹配。

\textbf{Geometry}对象包含一系列几何基元对象。
每个\textbf{geometry}对象都与一个bounding程序和一个intersection程序绑定，
这两个程序都在几何对象的基元之间共享。

\textbf{Material}对象包含有关着色操作的信息，包括在发现每个交叉点时调用的程序
（any hit program）和与光线原点最接近的交点对应的程序（closest hit program）。

\subsection{对象和数据模型}

OptiX采用了一个专用的对象模型，旨在最大限度地减少可编程操作使用的常量数据。
相较之下，OpenGL系统则一次只会使用一个着色器程序的组合。
然而，由于光线跟踪可以随机对物体和材料的数据进行访问。
因此OptiX允许上述的任意节点或对象携带一个表示为键-值对的数据集合，
而不是像OpenGL的着色语言一样采用了统一的全局变量。
变量由客户端应用程序设置并在执行跟踪期间是只读的。
这些变量可以是整数和浮点类型的标量或矢量（例如，float3，int4），
或者用户定义的结构，以及对缓冲区和纹理采样器的引用。

这些变量的继承机制是OptiX独有的。不像在面向对象语言中继承体中的self或者this指针，
OptiX引擎直接在遍历节点的时候跟踪当前的几何和材料对象。
变量值则从控制流中每个节点处于活动状态的对象中继承而来。
举例来说，一个intersection程序将继承来自geometry对象和geometry instance对象中的定义，
以及上下文中定义的全局变量。
从概念上讲，OptiX会在程序访问变量时通过键值对匹配的方式查找每个上述的节点。
这种机制可以被认为是一种大多数编程语言中都所使用的所谓嵌套作用域。
它在即时编译器中可以被非常高效地实现。

为了证明这个设计的作用，下面考虑这样一个例子：一些光源组成了一个光源数组。
通常，用户会在context中定义灯光，也就是将其作为OptiX的全局变量。
这使得此值可用于整个场景中的所有着色器。
但是，如果某个对象的灯光需要被重新覆盖，这时只需要在该几何实例中添加另一个名称完全相同的对象，
那么连接到那个对象的程序将使用覆盖值，而不是附在上下文中的全局变量。
这种机制十分强大，可以用于最小化场景数据，以便在具有最少缓存的体系结构上实现高性能。
由于在不同的渲染器之间对于这些情况的处理方式差异显著，
所以OptiX引擎在此只提供了一种对任意数量的重载规则都能有效表达的基本功能。

另外，通过一个用keyword属性标记特殊类型的变量，各个不同的程序（closest-hit, any-hit, intersection）之间也可以做到有效交流。
这个变量可以类比OpenGL中的可变变量，它被用于在求交程序和着色程序之间传递纹理坐标，法线和其他阴影信息。
这些变量具有特殊的语义 - 它们由intersection程序产生，但系统只会保留最近相交点的数据。
该机制使得求交程序和着色程序完全分离开来，支持多个同步基元和/或网格存储格式，同时也支持纹理，着色法线和用于计算光线微分的物体曲率。
任何不被closest hit和any hit使用的属性则都会被OptiX编译器直接删除。

\subsection{动态调度}

为了允许多次光线跟踪操作在单次执行中共存，OptiX采用了由用户定义的光线类型。
光线类型其实是一个简单的索引值，以在相交发生时从一组closest hit程序和any hit程序中做出选择。
这个可以用于例如将阴影射线与其他射线分开处理的情况。

类似地，OptiX允许定义多个入口函数，从而支持在同一个几何体集合上运行不同的通道。
例如，光子映射可能需要一个入口函数将光子投射到场景中，以及一个入口函数以投射用来观测的光线。

\subsection{缓冲和纹理}

对于批量数据存储的关键抽象是多维的缓冲区（buffer）对象，它表示了一个固定元素大小的一1维，2维或3维数组。
在任意程序中，一个缓冲区都可以通过C++包装器访问。
缓冲区可以是只读的、只写的或同时支持读写的，并且通过硬件支持原子操作。
缓冲区的实现基于句柄(handle-based)，因此不会公开原始指针，
因此OptiX运行时可以重新定位缓冲区以进行存储压缩，或促进其他内存空间的性能。
缓冲区通常用于输出图像，三角面片数据，光源列表和其他基于阵列的数据。
缓冲区也是唯一从OptiX程序输出数据的方法。
在大多数应用中，ray generation program将负责编写
数据到输出缓冲区中，但同时任何OptiX程序也可以在任何位置写输出缓冲区，只不过这些写入的顺序无法保证。
缓冲区也可以绑定到纹理采样器对象，这会启用GPU中处理材质的硬件。
缓冲区和纹理采样器对象可以绑定到OptiX变量，并使用和着色器值相同的那一套作用域机制。
此外，缓冲区和纹理采样器都可以与OpenGL和DirectX进行互动操作，从而有效地实现光栅化与光线跟踪的混合应用。

\section{系统概述}

OptiX引擎由两组不同的API组成，一个用于主机端，一个则是设备端的代码.
主机端的API是一组C函数，客户端应用程序通过调用这些函数来创建和配置上下文，组装节点图以及启动光线跟踪内核。
它也包括了一些管理用于内核执行的设备的接口。
另一个API（也被称为程序API）则是向用户程序公开的一些功能，
包括用于跟踪光线的函数调用，报告相交事件和访问数据等，
以及几个用于描述在光线跟踪中拥有特定作用的状态的语义变量，如当前点到最近相交点的距离。
对于调试，该API还提供了打印功能和异常处理的功能。

图5概述了OptiX应用程序的控制流程。在设置期间，应用程序调用OptiX主机API函数来提供场景数据，
例如几何，材料，加速结构，层次关系和程序等。
随后对rtContextLaunch API函数的调用将控制权传递给OptiX，其会对处理上下文中的更改进行处理。
如果需要的话，将对用户给定的程序重新编译以生成光线跟踪内核。
加速结构会被构建（或更新），而主机和设备之间的内存则会完成同步。
最后一步是执行光线跟踪内核，调用第3节中描述的各种用户程序。

执行光线跟踪内核完成后，其结果数据可以由应用程序来使用。
通常，这一步涉及读取用户程序填充的输出缓冲区，或者将其直接显示出来，例如通过OpenGL。
对于交互式或多通道应用程序来说，接着将重复从上下文设置开始的过程，
对上下文进行任意更改，然后再一次启动整个内核。

\section{加速结构}

在射线与场景中集合物体之间查找相交点的核心算法涉及对加速结构的遍历。
这种数据结构几乎对于每个光线追踪系统来说都是至关重要的组成部分。
它们通常是空间或对象的层次结构，遍历算法使用其来有效地搜索可能与给定光线相交的图元。 
OptiX对此提供了灵活的接口来控制加速结构，适用于广泛的应用。

\subsection{与节点图的交互}

在节点图中收集几何数据的原因之一是便于组织相关的加速结构。
相比在单个加速结构中维护所有场景的几何体，对场景中不同的区域构建多个结构显得更有意义。
例如，对于拥有动画效果的场景部分，需要为每个光线追踪通道都重建一份加速结构。
在这种情况下，为静态的区域单独创建一个结构可以提高效率。
除了只构造一个静态结构外，应用程序还可以花费更大的时间以构建更高质量的结构。

OptiX引擎将加速结构与节点图中的所有geometry group节点以及group节点相关联。
附加到geometry group节点上的结构是低层级的，构建在该几何组包含的几何图元上。
而附加到group节点的结构则是建立在该group所有子节点的包围盒上，因此代表了高层级的加速结构。
这些高级结构在用于表示修改频率不同的几何体之间的层次关系上十分有用。

\textbf{实例化}。加速结构系统的一个重要设计目标是支持灵活的实例化。
在这里，实例化指的是通过多次对几何相同的数据引用，而非直接复制大量的数据结构来实现低开销的场景复制功能。
如第3.2.1节中所述，图中的节点可以多次引用，这便自然地实现了实例化。
在不同实例之间，不仅共享几何信息，加速结构同样也可以共享。
与此同时，也可以为每个实例独立分配任意的非几何数据，例如材料程序和变量等等。

我们选择将附加到group和geometry group的加速结构公开为独立的API对象。
在实例化中的情况中，可以将单个加速结构附加到多个节点，从而共享其数据并避免相同数据结构的冗余构造。
该方法同样为运行时高效地添加和删除实例提供了支持。图6显示了一个具有实例化的节点图的示例。

\textbf{组合几何体上的加速结构}。
将场景划分为多个加速结构的场景减少了构建结构的时间但也减少了光线遍历场景图的性能。
如果场景被限制为完全静态的话，则通常只会选择一个加速结构。
一个geometry group的加速结构背后的构思是为了能在这样的设置中简化应用程序的数据管理：
用户可以把几何体与实例分开组织，然后用一个简单的geometry group将其组织起来，而
不是把所有的这些对象直接合并成一个单一的块中。相应的加速结构将构建在每个几何对象的各个基元上，
产生和把所有几何结构合成一起时一样高的效率。 
OptiX引擎将在内部处理必要的记录任务，例如对材料索引的正确重映射。

一个geometry group还可以在建立加速结构时利用某些对象内部的信息。
例如，在包含多个对象的几何组中，只有一个对象在在光线追踪的通道之间进行了修改， 
这时OptiX便可以考虑该信息并省略一些冗余操作（例如边界框计算，详细见5.3节）。

\subsection{加速结构的类型}

光线跟踪加速结构是一个相当活跃的研究领域。
没有一种类型在所有应用程序的所有条件下都是最佳的。
不同变体之间往往需要在光线跟踪性能与构造速度做出权衡，而每个应用程序具有不同的最佳选择。
因此，OptiX提供了多个不同的加速结构类型供应用程序选择。
节点图中的每个加速结构都可以是一种不同的类型，
既能支持高质量的静态结构，也能支持具有动态更新的结构。
大多数类型同样适用于高层次的结构，即连接到group的加速结构。

当前实现的加速结构包括重视层级质量的算法（例如SBVH [Stich等人。2009]），
重视创建速度的算法（例如LBVH [Lauterbach et al。2009]），以及介于两者之间的算法。

\subsection{创建}

每当一个加速结构的底层几何形状发生了变化，例如出现了动画效果，该加速结构便会被客户端应用程序显式标记为重建。
OptiX随后便会在rtContextLaunch API函数被调用时重新创建这些所有被标记了的加速结构。

创建加速结构的第一阶段是获得引用几何体的包围盒。
这一步通过为对象中的每个几何图元执行3.1节中描述的包围盒程序来完成，
这些程序会根据输入图元返回一个保守的轴对齐的包围盒。
使用这些包围盒作为加速结构的基本图元，便可以对在任意定义的几何体中（包括单个结构内几种类型的几何体）跟踪光线这一过程做出重要的抽象。
为在树中更高层级的group节点中获取必要的包围盒，这些图元的包围盒将会合并起来并以递归地传播下去。

第二个构造阶段则包括在给定包围盒的情况下构建实际的加速结构。
host和device的可并行性在这里可以通过两种方式得到利用。
首先，节点图中的多个加速结构可以并行构建，因为它们是相互独立的。
第二，单一加速结构的构建代码通常也可以并行化（参见[Shevtsov et al. 2007], [Zhouet al. 2008], [Lauterbach et al. 2009]）。
最终的加速结构数据会被放在设备中，供光线遍历(traversal)的代码所使用。

\subsection{调整}

虽然OptiX引擎中的加速结构被设计为开箱即用的模式，
有时仍然需要应用程序提供额外的信息以达到更高的实现效率。
因此，应用程序可以设置一些能够影响后续加速结构创建和光线遍历的特定属性。

这些属性中的一个例子是“refit”标志：如果一个使用BVH加速结构的几何体只是略有变化，
通常只需要简单地修改BVH的内部包围盒即可，而不是从头开始重建整个结构（参见[Lauterbach et al.2006]）。
客户端应用程序可以在某些类型的加速结构启用此功能，只要这能让预计的结果总运行时间减少。
关于这些的决策权被留给留给应用程序，因为这些程序通常拥有OptiX无法获得的上下文信息。

构建专门用于某些种类的几何图元的过程（不同于上面讨论的轴对其的包围盒）则是另一个这些属性能够起到作用的地方。
例如，某些应用可以通知SBVH加速结构，其底层的几何体仅由三角形组成，并且这些三角形的参数位于内存中。
那么SBVH便可以执行一个更加精确的构建层次结构的方法从而在结果上提高质量。