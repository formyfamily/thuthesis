\chapter{架构设计}
\label{cha:pipeline}

本章将主要对本人设计的GPU路径渲染平台进行架构方面的介绍。
首先，由于该平台建立在OpTiX的基础之上，因此会对该库进行简要的介绍。
接着，会从总体的角度阐述平台的框架设计思路以及类结构，
然后再逐一对框架的各个组成部分进行分析。

\section{OpTiX库介绍}

由于OpTiX是由Nvidia开发，因此其本质是一个基于CUDA通用并行语言上的API库。
下面的这张流程图，直观地展示了其内部的工作原理：

TODO: optix framework figure

在上图中，黄色的方框代表需要用户自己编写的CUDA程序，蓝色和灰色的部分则由OpTiX实现。
在用户通过rtContextLaunch开始渲染后，GPU会对其各个处理单元分别调用入口函数Ray Generation Program，并分配各自不同的索引。
该函数需要按照索引（通常和对应像素的坐标值一致）向场景中发射光线，接着调用rtTrace函数接口开始光线追踪流程。

对于每一根光线，OpTiX会在描述场景的结构图（Node Graph）中进行遍历，从而找到与之相交的物体。
在这其中，Node Graph Traversal负责递归查找，Acceleration Traversal负责利用包围盒等算法为求交过程加速，
而Selecor Visit Program则是由用户添加的一些遍历规则（本文中没有使用）。
如果某条光线和场景中一个物体的包围盒相交，系统便会进一步进入Intersection Program阶段，判断光线与物体是否相交。
如果是，系统会将该相交事件进行记录，同时调用一次与该物体相关的Any Hit Program。

在所有物体都完成遍历之后，如果没有任何相交出现，系统会调用一次Miss Program，否则针对最近的相交再调用一次Closest Hit Program。
在以上的三者中（对应图中的Shade部分），都可以再次调用rtTrace函数，从而进入光线追踪的下一层递归。
最后，如果在以上的任何步骤中出现了诸如栈溢出、违法防存的情况，则会立即终止所有程序，并直接调用Exception Program。
关于函数调用的情况大致便是这样。

除了运行流程外，还需要对OpTiX的几个重要数据结构（以OpTiX Prime++为准，在文档中这些结构又被统称为Handle）进行介绍。

首先要介绍的是Context（上下文）类。顾名思义，Context类是Host程序（即通过CPU运行的C++程序）和内核程序（运行在GPU上的CUDA程序）之间的桥梁。
Host程序需要将运行所需的所有数据、函数信息一并输入进该类的实际对象中，然后再通过调用这一对象的launch方法开始渲染。
在上述的几个CUDA程序中，Ray Generation Program和Miss Program是与Context直接进行绑定的。

其次是GeometryInstance（几何物体）类和Material（材质）类，前者表示场景中的各个物体，后者则对应着这些物体的材质。
每个GeometryInstance对象在创建时都需要绑定一个Intersection函数和Bound函数，分别用于该物体的求交计算和包围盒计算。
GeometryInstance对象还需要绑定一个或多个Material对象，并通过Intersection函数确定具体使用哪种材质进行计算。
另一方面，对于Material类而言，则需要绑定一个Closest Hit Program函数和一个Any Hit Program函数。
当判定相交的Intersection函数确定采用某一材质时，便会在之后调用它所绑定的这两个程序。

本文还使用到了GeometryGroup，Transform，Buffer，Program等许多其他数据结构，但在这里不再详细进行介绍。
最后，还需要说明一下OpTiX中的数据组织方式。

对于上述介绍的三种类型（Context，GeometryInstance，Material），除去由OpTiX规定的输入参数外，用户还可以添加其它所需的自定义数据。
这类数据的组织方式与Python语言中的Dict类似，采用字符串下标的哈希表维护。
用户可以输入的自定义数据格式包括但不限于：基本类型(int, float等)、向量类型(float3, matrix等)、
缓存数据（Buffer类）、以及自定义的函数指针（Program类）。不得不提的是，这其中的函数指针部分使得我们得以在最终的架构内实现多态。
这对本人实现渲染器的可拓展性起着决定性的作用。

\section{总体架构}
 
从需求上来说，本人期望实现的渲染器能够支持以下几个主要功能：

\begin{itemize}
    \item{能读取不同种类的场景文件}
    \item{能够支持多种不同的几何体、材质类型、摄像机以及渲染算法}
    \item{拥有图形界面，实现交互式渲染}
    \item{支持动态调整场景功能，并能够实现动画}
    \item{可以进行分布式渲染}
\end{itemize}

根据这些要求，最终框架设计成了如下图所示的结构（包括控制流、数据流）：

TODO: framework control / data flow figure

总体而言，该框架一共由四个模块组成：\textbf{Scene}，\textbf{Renderer}，\textbf{Post Processor}以及\textbf{GUI}。其中，
\textbf{Scene}的功能是将不同种类的输入场景文件进行读取，以及将数据转化成可被OpTiX使用的中间格式；
\textbf{Renderer}的功能是建立并配置OpTix中的Context类，将Scene中的所有数据输入到Context中，以及调用launch方法完成渲染工作；
\textbf{Post Processor}的功能是对Renderer的输出图像进行后处理，以及不断向Renderer提供反馈信息；
最后，\textbf{GUI}负责图形界面部分，将处理出来的图像展示到屏幕中，并处理由用户传来的交互数据。

除了模块结构外，同样还需要设计一套完整的工作流程。本框架制定的流程共分为6步：

\begin{enumerate}
    \item{用户启动渲染器，制定输入场景文件以及全局参数；}
    \item{根据输入的场景文件格式，建立Scene模块对文件进行解析；}
    \item{根据输入的全局参数，建立Renderer，并初始化Context类；}
    \item{将Scene中的数据，以及全局参数提供给Context；}
    \item{建立GUI，初始化渲染结果，然后开始以下循环：}
    \begin{enumerate}[\arabic{enumi}.1]
        \item{启动Renderer完成一轮渲染,并将结果进行累加；}
        \item{将累计结果输入Post Processor进行后处理；}
        \item{显示Post Processor的输出图像，同时向Renderer提交反馈；}
        \item{监控用户操作，如果场景或参数出现改动，则跳至第4步；}
    \end{enumerate}
    \item{保存结果，退出程序。}
\end{enumerate}

以上便是关于该架构的总体情况。下面将按照四个模块在流程中出现的顺序，依次对它们的设计细节进行阐述。
需要注意的是，后面的内容为了可能会为了功能扩展而对前面的结构进行修正，
因此最终的实现以本章结束时所得的版本为准。

\section{场景读取与载入}

TODO：Scene内所有结构的综合UML图

载入场景往往是一般渲染流程中工作量最为庞大的步骤之一，而对于GPU渲染器来说，这一步则显得更加困难。
这是因为，在从输入文件中读取数据的同时，我们还需要考虑如何将这些数据有效地组织起来，
从而使得GPU中的程序能够满足多态性，对各种各样的场景都能提供支持。
为了达到这点要求，我们首先便需要分析支持的场景应当由哪些部分组成：

\begin{itemize}
\item{各个物体的几何模型}
\item{物体上不同材质的属性（包括贴图）} 
\item{场景中不同介质的属性} 
\item{光源属性}
\item{摄像机的属性以及位置}
\item{以上所有属性随时间的变化情况（动画属性）}  
\end{itemize}

在OpTiX内的渲染流程中，使用这些属性的程序各有不同。
物体的几何模型在物体的两个求交函数中被用到；
材质属性、介质属性以及光源属性会在Closest Hit、Any Hit以及Ray Generation三类程序中得到使用；
摄像机的属性只会被用于Ray Generation程序；
动画属性仅仅被Host（CPU）所使用，因此不涉及任何GPU程序。
根据这些属性的应用范围，本架构提出了三种不同的抽象类\textbf{Geometry、Property、Animator}对它们进行封装。
其中，\textbf{Geometry}类用于几何模型；
\textbf{Property}类用于几何外的所有属性——材质、介质、光源、摄像机；
\textbf{Animator}类则用于属性变化。

\subsection{几何模型——Geometry}
TODO：Geometry的UML类图

由于我们的最终目标是将数据输入OpTiX中，所以可以反过来，从OpTiX的角度讨论如何设计Geometry。
对于OpTiX而言，建立一个GeometryInstance对象需要提供三种数据：
两个用于求交的函数（Program）、描述几何模型的参数（自定义参数）以及物体的材质（Material）。
可以发现，用于求交的函数往往只与Geometry的种类相关，因此这里看作是Geometry子类的一个静态变量。
几何模型的参数直接保存在各个实例中。
至于物体的材质，我们并不在Geometry中进行维护，而从调用它的地方直接取得。

综合上述，Geometry向外提供了一个直接生成GeometryInstance的方法buildGeometryInstance。
另外，在一些场合中可能需要对Geometry进行变换操作，因此还需要提供一个applyTransform方法。

\lstset{language=C++}
\begin{lstlisting}
virtual GeometryInstance buildGeometryInstance(Context&, vector<Material>&);
virtual void applyTransform(Transform&);
\end{lstlisting}

\subsection{场景属性——Property}
TODO：Property的UML类图

Property类是在场景输入当中最为重要的一环，它所解决的问题，是如何将不同种类的场景属性按照尽可能一致地输入进OpTiX中，从而使得所需的代码量达到最少。
这些属性往往由两部分组成，第一部分是数据，另一部分则是不同属性种类对应的计算函数。
举例来说，对于物体的材质而言，GPU中的内核程序既需要知道材质的各种参数（如颜色、反射率、光泽度等），
还得知道如何利用这些参数计算BRDF值，如何进行采样。
然而在GPU程序中，既不能通过指针参数的方式做到数据多态性，也不能通过虚函数的方式实现函数重载。
所以，在这里只能采用更加初级的方法来解决问题。

关于数据部分，本人最终采用的是通过OpTiX的Buffer输入给GPU的方法。
OpTiX的Buffer能够以数组的形式向内核程序传递任意类型的数据，但要求数组中所有元素的格式需要保持一致。
因此，这里采用了填充（Padding）的方式来对齐数据。定义Property的子类PaddingProperty，
其大小必须超过所有Property中的最大长度，来作为Buffer的数据类型。
对于内核程序而言，在拿到一个PaddingProperty类时，只需要知道它的实际类型（包含在Property类中），然后进行一次格式强制转换，便可以获得想要的数据了。

事实上，相较于上述的方法，还有一种看起来似乎更加直接的思路：和Geometry同样，利用OpTiX中添加自定义数据的方式来完成输入。
但是，本人最终没有采用这种方式，理由主要有两点（以材质属性为例）：第一，如果采用这种方案，材质属性应该被绑定在和它对应的Material中。
然而在一些渲染算法如SPPM中，Ray Generation程序也需要使用到这些属性，但由于该程序无法直接访问Material，因此这种方案并不能提供相应的支持；
第二，如果采用了这种方案，则不同种类的Material必须配置各自的Closest Hit Program，来使用该类型的属性，
这便使得代码量变得冗长许多。而相比之下，上面的方法只需要用到一个程序即能达成目标。

这就涉及到关于Property设计的第二部分——如何重载属性的计算函数。这里本框架采用的是函数指针的方式。
OpTiX中的函数指针实际是通过函数ID（rtCallableProgramId）来表示的，这个ID同样是Buffer支持的数据类型之一。
在渲染开始之前，Host程序会对所有可能出现的计算函数都计算函数ID，然后保存在对应的Buffer之中；
到了渲染时，内核程序只需要知道属性的类型，便可以在Buffer里面查找对应的函数，然后直接进行调用。

根据四种不同的属性，Property一共拥有四个子类：\textbf{MaterialProperty}，\textbf{LightProerty}，\textbf{CameraProperty}以及\textbf{MediumProperty}。
这四者在结构上基本保持一致，它们又拥有着属于各自的子类。限于篇幅，有关这些不同Property的内部实现，这里便不再进行逐一介绍。

最后需要提到的一点是，和Geometry不同，Property作为数据结构，需要直接出现在内核程序之中。
然而，将这些Property输入OpTiX的方法（比如说生成Material）却涉及到OpTiX的Host代码，因此不能被引入内核程序，这就引发了矛盾。
为了解决这个矛盾，本人又加入了一个新的类PropertyManager，来封装所有需要Host程序完成的工作。PropertyManager一共提供了三个函数接口：

\lstset{language=C++}
\begin{lstlisting}
void importPropertyBuffer(Context);
void changePropertyBuffer(int);
virtual void importPropertyProgram(Context);
\end{lstlisting}

其中，importPropertyBuffer函数将已有的Property（保存在PropertyManager中）通过填充方法放入Buffer之中；
changePropertyBuffer函数将Buffer中指定下标的Property的数据进行更新；
而importPropertyProgram函数则负责把与Property相关的所有计算函数输入OpTiX中。
和Property一样，PropertyManager也有着相应的四个子类，但这些子类之间有着更大的差异（如LightPropertyManager还会维护光源的Geometry）
且都没有被进一步继承下去。

\subsection{动画——Animator（未实现）}
TODO：动画

\subsection{场景——Scene}
Scene类表示的是整个场景中的所有信息。从之前列举的场景内容来看，
它需要包含一个Geometry组成的数组、四种不同的PropertyManager，和一个Animator。
在功能上，它应当支持两个操作：从文件中读取数据，以及将数据放入到OpTiX的Context中。这两个操作对应的接口函数为：
\lstset{language=C++}
\begin{lstlisting}
virtual void loadScene(Context);
virtual void importSceneToContext(Context, vector<Program>&);
\end{lstlisting}

这里有两点需要做出特殊说明。首先，从设计上来说，在读取文件时不应当需要使用Context作为参数，
但是这里加入了Context，主要是为了在一些地方（如Mesh读取出）提前获取Buffer的地址，从而避免在读取完后再进行数据拷贝；
其次第二个函数的参数中加入了一个Program数组，这些Program实际是由之后介绍的Renderer所确定的Closest Hit Program和Any Hit Program，
由于这两者必须被绑定到由Scene生成的Material上，所以这里它们也需要作为参数传进来。

\section{渲染器——Renderer}
TODO：Renderer的UML类图

Renderer类的主要任务是生成并初始化Context，及完成渲染工作。事实上，有了之前Scene的基础，它在实现上相对简单许多。
Renderer需要维护的数据包括但不限于由它生成的Context，与渲染算法相关的Hit Program，以及所有用于渲染的输入、输出Buffer。
此外，它还需要支持以下的四个接口函数：

\lstset{language=C++}
\begin{lstlisting}
virtual void generateContext();
virtual void uploadScene(Scene&);
virtual void resize(uint, uint);
virtual void launch();
\end{lstlisting}

函数generateContext的功能便是是建立Context。为了让Context能够运转，在该函数中还要根据不同的渲染算法，
设定Context的全局参数、创建输入输出的Buffer、以及为Context指定Ray Generation、Exception和Miss三种程序。
另外，该函数还会生成用于后方的两种Hit Program。

函数uploadScene的主要目的是调用上述的importSceneToContext函数，但初次之外，一些需要Scene的属性（如包围盒大小）
来决定的Renderer参数也会在这里面被设置。

函数resize是为了在图形界面中，支持用户对窗口进行放缩的操作。具体内容主要包括修改相机参数、各种图像Buffer的尺寸大小等等。

最后也是最为重要的函数launch，其功能便是用OpTiX完成一轮渲染。
在这个函数中，将会一次或多次调用Context的launch接口，启动OpTiX的GPU渲染程序。
在下一章GPU光线追踪渲染算法的介绍中，会对这个函数内部的实现进行更细致的说明。

\section{图像后处理——PostProcessor}



\section{图形界面——GUI}

