\chapter{基于GPU的光线追踪渲染}
\label{cha:algorithms}

上一章介绍了渲染器的整体架构以及Host程序中的各种关键类，
接下来则分析如何用OpTiX中的GPU程序实现具体的渲染算法。
本人先会对需要实现的算法原理、公式进行简单介绍，然后逐步解释算法中的各个步骤是怎样完成的。

\section{路径追踪算法}
路径追踪算法的原理是利用蒙特卡洛积分法近似求解渲染方程(式2-1)。
展开来说，当光线在场景中与物体相交时，
我们可以按照一定的概率密度函数$p(\omega)$对次级光线的角度$\omega_i$进行采样，
然后通过下式来求得该光线所得的出射光照亮度近似值：
\begin{equation}
L_o(\textbf{x}, \omega_o) 
\approx \frac{1}{N}\sum_{k=1}^{N}\frac{L_i(\textbf{x}, \omega_i)f(\textbf{x}, \omega_o, \omega_i)|cos\theta_i|}{p(\omega_i)}
\end{equation}
其中$N$为采样个数，$L_i$为入射光照亮度，而$f$则为材质的BSDF函数。
为求方便，通常会用$\beta_i=\frac{f(\textbf{x}, \omega_o, \omega_i)|cos\theta_i|}{p(\omega_i)}$直接表示$L_i$对$L_o$的影响系数。
对于经过多次散射的路径而言，只需要计算出路径中每次采样对应的$\beta$之乘积，
然后再与路径终点处的光照亮度相乘，便可以获得路径起点处的亮度估计值。

\subsection{算法流程}
\label{cha:pathtrace}

为了方便描述，我们先将场景中的光源简化为单一点光源，其位置为$\textbf{x}_{lt}$，对各个方向的辐射亮度均为$L_e$。

在上面的公式中，一共有三个部分需要通过材质而求得：它们分别是采样值$\omega_i$、
采样的概率密度值$p(\omega_i)$以及BRDF值$f(\textbf{x}, \omega_o, \omega_i)$。
为此，我们对\textbf{MaterialProperty}添加三个对应的计算函数：Sample函数，Pdf函数和Eval函数。
这些函数的输入包含材质属性（\textbf{PaddingMaterialProperty}），相交点的信息（位置、向量等）以及当前光线所携带的其它信息。

我们首先定义路径追踪算法使用的Closest Hit Program。由于场景中只含有点光源，因此我们先只需要考虑光线和非光源物体相交的情况。
该函数的流程如算法\ref{CHPPath}所示：
\begin{algorithm}
    \SetKwInOut{KIN}{输入}
    \SetKwInOut{KDATA}{输出}
    \caption{路径追踪Closest Hit Program}
    \label{CHPPath}
    \KIN{相交点位置及法向量$\textbf{x},\textbf{n}$，出射光线角$\omega_o$，系数乘积$\beta$，光照亮度$L_o$}
    \KDATA{入射光线起点$\textbf{x}_i$，入射光线方向$\omega_i$，系数乘积$\beta$，光照亮度$L_o$}

    获取物体的材质属性$mat$(PaddingMaterialProperty)；\\
    根据材质的种类，在保存函数ID的Buffer中取出对应的三个计算函数；\\
    \If {$\textbf{x}$与$\textbf{x}_{lt}$之间没有其它物体遮挡} 
    {
        $\omega_{lt} \leftarrow \frac{\textbf{x}_{lt}-\textbf{x}}{|\textbf{x}_{lt}-\textbf{x}|}$；\\
        $L_o \leftarrow L_o+\beta\cdot L_e\cdot {\rm Eval}(mat, \textbf{n}, \omega_o, \omega_{lt}) $；
    }
    $\omega_i \leftarrow {\rm Sample}(mat, \textbf{n}, \omega_o)$；\\
    $\textbf{x}_i \leftarrow \textbf{x}$；\\
    $\beta \leftarrow \beta\cdot {\rm Eval}(mat, \textbf{n}, \omega_o, \omega_i)/ {\rm Pdf}(mat, \textbf{n}, \omega_o, \omega_i)$；\\
\end{algorithm}

这里需要补充一下算法中第3步的详细内容：
这一步骤会创建一条阴影光线(Shadow Ray)并调用rtTrace对其跟踪，
然后通过Any Hit Program来判断该相交点是否被其它物体所遮挡。

接下来要描述的内容是Ray Generation Program。首先，我们需要对rtTrace函数的格式进行定义：
我们规定rtTrace的输入包含光线信息（起点、方向）和用户的其他自定义输入，输出则包含次级光线信息和用户的其他自定义输出。
其中，用户自定义输入（出）的内容应当和Closest Hit Program中除由OpTiX生成的信息之外的输入（出）保持一致。

另外，由于这里要通过相机生成初始光线，因此需要在\textbf{CameraProperty}中添加一个计算函数CameraSample。
该函数以相机参数及运行时的索引作为输入，而以光线的起点$x$、方向$\omega_o$作为输出。

Ray Generation Program的实现详见算法\ref{RGPPath}，至此路径追踪算法最重要的核心部分均以完成。
\begin{algorithm}
    \SetKwInOut{KIN}{输入}
    \SetKwInOut{KDATA}{数据}
    \SetKwInOut{KOUT}{输出}
    \caption{路径追踪Ray Generation Program}
    \label{RGPPath}
    \KIN{索引$index_{x,y}$}
    \KDATA{累计平均光照亮度$L_{acc}$，总采样数$S$}
    \KOUT{光照亮度$L_{out}$}

    获取相机属性$cam$(PaddingCameraProperty)；\\
    根据相机种类，取出对应的CameraSample函数；\\
    $(\textbf{x}, \omega_o) \leftarrow {\rm CameraSample}(cam, index_{x,y})$；\\
    $\beta \leftarrow 1$；\\
    $L_o \leftarrow 0$；\\
    $d \leftarrow 0$；\\
    \For{$d < d_{max}$}
    {
        $(\textbf{x}, \omega_o, \beta, L_o) \leftarrow {\rm rtTrace}(\textbf{x}, \omega_o, \beta, L_o)$；\\
        $d \leftarrow d+1$； \\
    }
    $L_{acc} \leftarrow (L_o+L_{acc}\cdot S)/(S+1)$；\\
    $L_{out} \leftarrow L_{acc}$；\\
    $S \leftarrow S+1$；
\end{algorithm}

\subsection{光照计算}

之前为了方便描述算法，我们对场景中的光源提出了限定，这一节的内容则是讨论如何将这一限定去除。

首先我们需要回顾一下在\ref{PathTracingOptimization}小节中提到过的复合重要性采样算法。
该算法的基本思路是，在对一个函数$f$使用蒙特卡洛积分法求积分时，
我们可以采用多种不同的采样策略（即不同的概率密度函数）进行采样，然后按照下式对所有策略的采样结果进行合并：
\begin{equation}
    \sum_{s=1}^{M} \sum_{i=1}^{N_s}\frac{f(X_{si})w_s(X_{si})}{p_s(X_{si})}
\end{equation}
其中$w_s$是权重函数，其值一般设置为：
\begin{equation}
    w_s(x) = \frac{(N_sp_s(x))^2}{\sum_i(N_ip_i(x))^2}
\end{equation}
利用这个方法，路径追踪算法便可以有效地渲染含有面光源的场景了。
我们采用两种采样策略来计算直接光照：第一种策略是按照光源的能量分布在光源表面采样，然后计算采样点向相交点传输的辐射亮度；
第二种策略则是按照物体表面的BRDF进行次级光线的采样，然后计算光源通过次级光线向物体传输的辐射亮度。
在实现中，对于每条路径两种策略都只会进行一次采样。

对于第一种策略，我们通过对Closest Hit Program中的第3-6步进行修改来完成。
由于要对光源进行采样，所以LightProperty需要添加LightSample函数和LightPdf函数，
需要注意的是，LightSample函数的采样结果是点而非方向。
另外，还需要加入LightEval函数，用来求光源上某点朝某个方向输出的辐射亮度。
修改过后的算法具体步骤详见算法\ref{Light1}。
对于第二种策略，则通过增加光源物体的Closest Hit Program来实现，详见算法\ref{Light2}：

\begin{algorithm}
    \SetKwInOut{KIN}{输入}
    \SetKwInOut{KDATA}{输出}
    \caption{光照计算（策略一）}
    \label{Light1}
    \KIN{相交点位置及法向量$\textbf{x},\textbf{n}$，出射光线角$\omega_o$，系数乘积$\beta$，光照亮度$L_o$}
    \KDATA{光照亮度$L_o$}

    获取光源属性$light$(PaddingLightProperty)；\\
    根据光源的种类，取出对应的三个计算函数；\\
    $(\textbf{x}_{lt}, \textbf{n}_{lt}) \leftarrow {\rm LightSample}(light)$；\\
    $\omega_{lt} \leftarrow \frac{\textbf{x}_{lt}-\textbf{x}}{|\textbf{x}_{lt}-\textbf{x}|}$；\\
    $p_{lt} \leftarrow {\rm LightPdf}(light, \textbf{x}_{lt})$；\\
    $p_m \leftarrow {\rm Pdf}(mat, \textbf{n}, \omega_o, \omega_{lt})$；\\
    $w_l \leftarrow \frac{p_{lt}^2}{(p_{lt}^2+p_m^2)}$；\\
    \If {$\textbf{x}$与$\textbf{x}_{lt}$之间没有其它物体遮挡} 
    {$L_o \leftarrow L_o+\beta\cdot(w_l/p_{lt})\cdot {\rm LightEval}(light, \textbf{n}_{lt}, \omega_{lt})\cdot {\rm Eval}(mat, \textbf{n}, \omega_o, \omega_{lt}) $；} 
\end{algorithm}
\begin{algorithm}
    \SetKwInOut{KIN}{输入}
    \SetKwInOut{KDATA}{输出}
    \caption{光照计算（策略二）}
    \label{Light2}
    \KIN{相交点位置及法向量$\textbf{x},\textbf{n}$，出射光线角$\omega_o$，系数乘积$\beta$，光照亮度$L_o$，上轮对材质采样的概率密度值$p_m$}
    \KDATA{光照亮度$L_o$}

    获取光源属性$light$(PaddingLightProperty)；\\
    根据光源的种类，取出对应的三个计算函数；\\
    $p_{lt} \leftarrow {\rm LightPdf}(light, \textbf{x})$；\\
    \eIf {无可用的$p_m$} 
    {
        $L_o \leftarrow L_o+\beta\cdot{\rm LightEval}(light, \textbf{n}_{lt}, \omega_{lt}) $；
    } 
    {
        $w_l \leftarrow \frac{p_m^2}{(p_{lt}^2+p_m^2)}$；\\
        $L_o \leftarrow L_o+\beta\cdot w_l\cdot {\rm LightEval}(light, \textbf{n}_{lt}, \omega_{lt}) $；
    }
\end{algorithm}

\section{随机自适应光子映射算法}

光子映射算法的核心思想，是通过发射光子+区域查找的方法来近似场景中的间接光照分布。
由于从头开始介绍该类算法需要花费大量功夫，因此这里只对最终实现的随机自适应光子映射算法（SPPM算法）进行简单陈述。

首先，我们需要对直接光照和间接光照两个概念进行精确的定义。
在本章中，直接光照指从光源出发，只经过镜面材质（或只在第一次经过漫反射材质）然后达到相机的光照（路径表达式为$LDS^*C$或$LS^*C$），
而间接光照则对应其余所有光照(路径表达式为$L(S|D)^+D(S|D)^*C$)。
在本人的实现中，直接光照采用路径追踪算法直接求得，而间接光照则通过光子来计算。

SPPM算法是一个渐进算法，因此需要进行多轮运算才能达到收敛。
每一轮的运算又具体分为三步：
第一步被称为光子通道（Photon Pass），由光源生成大量光子，并对这些光子进行追踪；
第二步将场景中的光子储存在一个按空间划分的数据结构中（例如KD树），该结构又被称为光子图（Photon Map）；
最后一步被称为聚集通道（Gather Pass），即运行路径追踪算法进行渲染，并在光线遇到漫反射材质时，根据相交点周围的光子计算间接光照。
由于第一、三步需要光线追踪功能，因此在本框架中由OpTiX完成；第二步则通过Host程序完成。

\subsection{光子通道}

有了之前的基础，实现光子通道这一步只需要再新增一个Ray Generation程序即可。
另外，光子的生成需要在起点位置和方向两方面都进行采样，
所以还要在LightProperty中加入两个计算函数LightDirSample及LightDirPdf以提供支持。

关于光子通道的流程详见算法\ref{RGPPPass}。这里需要解释一下$\beta'$的作用：
由于保存在光子图中的光子信息不包含最后一轮材质采样的结果，
因此在计算光子能量的时候需要使用到上一轮迭代生成的$\beta$值。

\begin{algorithm}
    \SetKwInOut{KIN}{输入}
    \SetKwInOut{KDATA}{输出}
    \caption{光子通道Ray Generation Program}
    \label{RGPPPass}
    \KIN{索引$index_{x,y}$}
    \KDATA{光子图${\rm pmap}$}

    获取光源属性$light$(PaddingLightProperty)；\\
    根据光源的种类，取出对应的五个计算函数；\\
    $(\textbf{x}_{lt}, \textbf{n}_{lt}) \leftarrow {\rm LightSample}(light)$； \\
    $\omega_{lt} \leftarrow {\rm LightDirSample}(light, \textbf{n}_{lt})$； \\
    $p_{lt} \leftarrow {\rm LightPdf}(light, \textbf{x}_{lt})\cdot {\rm LightDirPdf}(light, \textbf{n}_{lt}, \omega_{lt})$； \\
    $\beta, \beta' \leftarrow 1$；\\    
    $d \leftarrow 0$；\\
    \For{$d < d_{photon\_max}$}
    {
        $(\textbf{x}_{lt}, \omega_{lt}, \beta, \_) \leftarrow {\rm rtTrace}(\textbf{x}_{lt}, \omega_{lt}, \beta, \_)$；\\
        \If{Closest Hit Program中的物体材质是漫反射材质}
        {    
            ${\rm append}\Big({\rm pmap}, (\textbf{x}_{lt}, \omega_{lt}, \beta' / p_{lt})\Big)$；\\
            $d \leftarrow d+1$；
        }
        $\beta' = \beta$。
    }

\end{algorithm}

\subsection{维护光子图}
之前一步得到的光子图，实际上只是一个由诸多光子组成的列表，
这一步的任务则是要将该列表重新组织成KD树的结构。
由于这里的工作完全是由Host程序实现，且KD树的搭建属于经典算法，因此就不进行详细说明了。

要注意的一点是，这一步生成的KD树最终是通过怎样的结构来保存的。
这里本人采用的是由单数组表示的二叉树结构，并保存在一个\textbf{Buffer}之中，这样有便于后续的GPU程序对其展开搜索。

\subsection{聚集通道}

SPPM算法的聚集部分可以概括为以下几个公式\cite{StochasticProgressivePhotonMapping}：
\begin{align}
    N_{i+1} &= N_{i}+\gamma M_i \label{SPPM1}\\
    r_{i+1} &= r_i\sqrt{\frac{N_{i+1}}{N_i+M_i}} \label{SPPM2}\\
    \tau_{i+1} &= (\tau_i+\sum_{j = 1}^{M_i}\beta_jf(\textbf{x},\omega_o, \omega_j))\frac{r_{i+1}^2}{r_i^2} \label{SPPM3}\\
    L_i &= \frac{\tau_i}{N_{sum}\cdot \pi r_i^2}  
\end{align}
其中$r_i$代表搜索半径，$N_i$代表总共找到的光子数，
$M_i$代表本轮迭代中在半径$r_i$内搜索到的光子总数，$\tau_i$代表所有搜索到的光子带来的光通量总和，
$N_{sum}$代表总共发出的光子数，而$L_i$代表最终求得的间接光照亮度。

这一部分的实现可以通过对\ref{cha:pathtrace}中提到的两个程序进行一些修改来完成。
对于Closest Hit Program来说，只需要在返回值中添加当前材质的属性（MaterialProperty）即可；
而Ray Generation Program的改动则相对更多，算法\ref{RGPGather}描述了修改过后的具体版本。

\begin{algorithm}
    \SetKwInOut{KIN}{输入}
    \SetKwInOut{KDATA}{数据}
    \SetKwInOut{KOUT}{输出}
    \caption{聚集通道Ray Generation Program}
    \label{RGPGather}
    \KIN{索引$index_{x,y}$，已发射的光子总数$N_{sum}$}
    \KDATA{累计平均光照亮度$L_{acc}$，总采样数$S$，搜索半径$r_i$，收到光子数$N_i$，光子光通量总和$\tau_i$}
    \KOUT{光照亮度$L_{out}$}
    生成初始光线$(\textbf{x}, \omega_o)$，设定初始值$\beta,L_o,d$；\\
    $\beta' \leftarrow 1$；\\
    \For{$d < d_{max}$}
    {
        $(\textbf{x}, \omega_o, \beta, L_o, mat) \leftarrow {\rm rtTrace}(\textbf{x}, \omega_o, \beta, L_o)$；\\
        \If{$mat$是漫反射材质}
        {
            取得$mat$的Eval计算函数；\\
            $M_i \leftarrow 0$；\\
            $\Phi_i \leftarrow 0$；\\
            \For{$\textbf{x}$周围$r_i$半径内的光子$(\textbf{x}_{ph}, \omega_{ph}, L_{ph})$}
            {
                $\Phi_i \leftarrow \Phi_i + \beta' \cdot L_{ph}\cdot {\rm Eval}(mat, \textbf{x}, \omega_o, \omega_{ph})$\\
                $M_i \leftarrow M_i+1$；
            }
            按照式\ref{SPPM1},式\ref{SPPM2},式\ref{SPPM3}更新$r_i, N_i,\tau_i$；\\
            \textbf{break}\\
        }
        $d \leftarrow d+1$； \\
        $\beta' \leftarrow \beta$；\\
    }
    $L_{acc} \leftarrow (L_o+L_{acc}\cdot S)/(S+1)$；\\
    $L_{out} \leftarrow L_{acc}+\tau_i/(N_{sum}\cdot \pi r_i^2)$；\\
    $S \leftarrow S+1$；
\end{algorithm}

至此，关于SPPM算法的GPU实现已基本介绍完毕。

\section{渲染优化}

除去以上的两个渲染算法外，本人还实现了两个渲染优化算法，这里也进行一些简单说明。

\subsection{基于深度学习的图像去噪}

基于之前提到的工作\cite{NvidiaDenoiser}，新版的OpTiX库加入了深度学习的去噪功能，
本人则将其进一步封装成了一个\textbf{PostProcessor}类(名为\textbf{DLDenoiser})。
由于该去噪功能对应的模块在设计上与OpTiX的光线渲染模块基本互相独立，且只要调用几个简单的API函数就可以使用，
因此这里不再介绍其具体的使用流程。
要注意的一点是，该去噪器的输入除去渲染生成的RGB结果外，还包括相交点位置、相交点向量、Albedo等辅助信息，
因此还需要修改Renderer使其输出些数据。

\subsection{基于方差估计的自适应渲染算法}

\label{adaptive}

该算法源自于2009年Holger Dammertz等人的工作\cite{AdaptiveSampling}，主要作用与路径追踪算法上。
大致来说，该算法会将所有已有的渲染结果按照轮数的奇偶分成两部分，各自累加后求差，从而估计图像上各个像素点的亮度方差值。
对于图像中的某一个像素块（这些块具体如何生成详见原文），如果其内部的像素方差平均值达到足够小，便在后续的渲染中不再对该块继续进行采样。

该算法的实现也被封装在一个\textbf{PostProcessor}类中，名为\textbf{AdaptiveSamplingProcessor}。
该类以\textbf{Renderer}在奇偶轮数下的累计结果作为额外输入数据，
而将每个像素是否终止的信息作为对\textbf{Renderer}的反馈。
其process函数实现的内容即根据输入计算各个像素是否需要终止，但不会对渲染器原本的输出图像进行任何修改。

对于Optix程序的修改则主要集中在Ray Generation程序上，共有两点：
第一点是需要根据\textbf{AdaptiveSamplingProcessor}发送过来的反馈信息决定是否对当前像素进行渲染；
第二点则是需要额外输出奇偶轮数下的累计光照亮度。

%A Hierarchical Automatic Stopping Condition forMonte Carlo Global Illumination